SA with Beta = 

Feature values of SA are all close to 0 (choose better beta)

python main_bovgru.py 
OF20 BOV GRU HA without Embedding...
EPOCHS = 30 : HIDDEN_SIZE = 256 : GRU LAYERS = 2
SEQ_SIZE : 30 :: CLUSTER_SIZE : 1000
100%|█████████████████████████████████████████| 423/423 [01:06<00:00,  6.34it/s]
100%|█████████████████████████████████████████| 423/423 [01:03<00:00,  6.67it/s]
Epoch 0/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1221 Acc: 0.0691
test Loss: 0.1215 Acc: 0.0781

Epoch 1/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 2/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 3/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 4/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 5/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 6/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 7/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 8/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 9/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 10/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 11/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 12/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 13/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1215 Acc: 0.0781

Epoch 14/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 15/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 16/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 17/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 18/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 19/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 20/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1216 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 21/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1216 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 22/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1216 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 23/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 24/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 25/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 26/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1217 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 27/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1216 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 28/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1216 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Epoch 29/29
----------
Category Weights : [17101.0, 2935.0, 888.0, 4935.0, 3445.0, 8262.0, 3321.0, 3242.0, 3253.0, 4202.0, 4230.0, 3838.0, 1978.0, 3396.0, 2743.0, 3551.0, 3585.0, 778.0, 3461.0, 1539.0, 1229.0, 1919.0, 9514.0, 11294.0, 4426.0, 9675.0, 3543.0, 2131.0, 4398.0, 4383.0, 4782.0, 8847.0, 2744.0, 3469.0, 3920.0, 12670.0, 5110.0, 3917.0, 4456.0, 2734.0, 8435.0, 2948.0, 3014.0, 8321.0, 3832.0, 4771.0, 8536.0, 5421.0, 2449.0, 4333.0, 3657.0]
train Loss: 0.1216 Acc: 0.0708
test Loss: 0.1216 Acc: 0.0781

Training complete in 103m 55s
Best val Acc: 0.078142
Model saved to disk... : logs/bovgru_SA_of20_Hidden256/gru_classifier_ep30_S30C1000_SGD.pt
Loading Encoder weights... : logs/bovgru_SA_of20_Hidden256/gru_classifier_ep30_S30C1000_SGD.pt
Total Execution time for 30 epoch : 6234.937893152237
##############################
GRU Sequence Classification Results:
30/1516 Correct
Accuracy = 0.01978891820580475 
Confusion matrix
[[30. 30. 30. ... 30. 30. 30.]
 [ 0.  0.  0. ...  0.  0.  0.]
 [ 0.  0.  0. ...  0.  0.  0.]
 ...
 [ 0.  0.  0. ...  0.  0.  0.]
 [ 0.  0.  0. ...  0.  0.  0.]
 [ 0.  0.  0. ...  0.  0.  0.]]
#Parameters : 3259443 
************************************************************
SEQ_SIZES : range(30, 31, 2)
Accuracy values : [0.01978891820580475]


python main_bovgru.py 
OF20 BOV GRU HA without Embedding...
EPOCHS = 30 : HIDDEN_SIZE = 256 : GRU LAYERS = 2
SEQ_SIZE : 30 :: CLUSTER_SIZE : 100
100%|█████████████████████████████████████████| 423/423 [01:02<00:00,  6.79it/s]
100%|█████████████████████████████████████████| 423/423 [01:04<00:00,  6.58it/s]
Epoch 0/29
----------
Category Weights : [1280.0, 1245.0, 1219.0, 1268.0, 1264.0, 1208.0, 1234.0, 1302.0, 1254.0, 1262.0, 1245.0, 1205.0, 1283.0, 1235.0, 1292.0, 1257.0, 1244.0, 1236.0, 1231.0, 1251.0, 1294.0, 1244.0, 1275.0, 1252.0, 1261.0, 1297.0, 1219.0, 1260.0, 1265.0, 1255.0, 1256.0, 1292.0, 1274.0, 1240.0, 1249.0, 1265.0, 1212.0, 1251.0, 1260.0, 1320.0, 1272.0, 1228.0, 1280.0, 1288.0, 1240.0, 1283.0, 1265.0, 1245.0, 1218.0, 1227.0, 1230.0]
train Loss: 3.9336 Acc: 0.8595
test Loss: 3.9333 Acc: 1.0220

Epoch 1/29
----------
Category Weights : [1240.0, 1318.0, 1292.0, 1278.0, 1278.0, 1286.0, 1220.0, 1272.0, 1250.0, 1321.0, 1310.0, 1229.0, 1194.0, 1228.0, 1265.0, 1222.0, 1217.0, 1273.0, 1272.0, 1273.0, 1322.0, 1233.0, 1213.0, 1234.0, 1278.0, 1239.0, 1203.0, 1275.0, 1250.0, 1211.0, 1237.0, 1314.0, 1243.0, 1231.0, 1251.0, 1280.0, 1220.0, 1251.0, 1260.0, 1259.0, 1327.0, 1254.0, 1228.0, 1322.0, 1237.0, 1228.0, 1241.0, 1223.0, 1285.0, 1200.0, 1245.0]
train Loss: 3.9329 Acc: 1.5395
test Loss: 3.9327 Acc: 1.0570

Epoch 2/29
----------
Category Weights : [1284.0, 1290.0, 1263.0, 1202.0, 1313.0, 1243.0, 1249.0, 1274.0, 1240.0, 1227.0, 1310.0, 1308.0, 1239.0, 1216.0, 1216.0, 1272.0, 1175.0, 1297.0, 1277.0, 1186.0, 1236.0, 1261.0, 1240.0, 1315.0, 1222.0, 1253.0, 1227.0, 1212.0, 1219.0, 1221.0, 1270.0, 1248.0, 1255.0, 1189.0, 1220.0, 1182.0, 1295.0, 1277.0, 1290.0, 1317.0, 1277.0, 1290.0, 1341.0, 1244.0, 1266.0, 1280.0, 1284.0, 1307.0, 1241.0, 1225.0, 1247.0]
train Loss: 3.9285 Acc: 1.6260
test Loss: 3.9268 Acc: 0.5915

Epoch 3/29
----------
Category Weights : [1265.0, 1267.0, 1206.0, 1175.0, 1280.0, 1269.0, 1273.0, 1235.0, 1259.0, 1224.0, 1246.0, 1227.0, 1228.0, 1249.0, 1258.0, 1205.0, 1275.0, 1249.0, 1270.0, 1284.0, 1213.0, 1247.0, 1289.0, 1254.0, 1266.0, 1322.0, 1215.0, 1275.0, 1251.0, 1273.0, 1231.0, 1233.0, 1350.0, 1297.0, 1226.0, 1261.0, 1231.0, 1210.0, 1266.0, 1291.0, 1282.0, 1263.0, 1246.0, 1282.0, 1277.0, 1232.0, 1277.0, 1268.0, 1226.0, 1236.0, 1298.0]
train Loss: 3.9117 Acc: 1.4930
test Loss: 3.9326 Acc: 0.6935

Epoch 4/29
----------
Category Weights : [1231.0, 1182.0, 1272.0, 1284.0, 1258.0, 1236.0, 1265.0, 1297.0, 1260.0, 1161.0, 1292.0, 1259.0, 1233.0, 1242.0, 1256.0, 1286.0, 1298.0, 1281.0, 1279.0, 1255.0, 1308.0, 1272.0, 1222.0, 1237.0, 1268.0, 1249.0, 1288.0, 1242.0, 1204.0, 1276.0, 1234.0, 1236.0, 1261.0, 1308.0, 1197.0, 1272.0, 1218.0, 1256.0, 1258.0, 1217.0, 1280.0, 1228.0, 1257.0, 1266.0, 1279.0, 1242.0, 1297.0, 1223.0, 1254.0, 1251.0, 1305.0]
train Loss: 3.8999 Acc: 1.9900
test Loss: 3.9246 Acc: 0.9495

Epoch 5/29
----------
Category Weights : [1243.0, 1251.0, 1272.0, 1251.0, 1252.0, 1202.0, 1293.0, 1266.0, 1263.0, 1259.0, 1294.0, 1281.0, 1260.0, 1210.0, 1294.0, 1342.0, 1204.0, 1232.0, 1258.0, 1223.0, 1270.0, 1216.0, 1286.0, 1220.0, 1280.0, 1246.0, 1313.0, 1222.0, 1204.0, 1240.0, 1252.0, 1228.0, 1268.0, 1229.0, 1276.0, 1263.0, 1237.0, 1272.0, 1288.0, 1209.0, 1293.0, 1237.0, 1272.0, 1216.0, 1269.0, 1208.0, 1271.0, 1268.0, 1248.0, 1307.0, 1274.0]
train Loss: 3.8846 Acc: 2.5700
test Loss: 3.9185 Acc: 1.3515

Epoch 6/29
----------
Category Weights : [1267.0, 1215.0, 1230.0, 1316.0, 1211.0, 1284.0, 1258.0, 1262.0, 1288.0, 1241.0, 1277.0, 1200.0, 1214.0, 1295.0, 1228.0, 1292.0, 1243.0, 1262.0, 1226.0, 1260.0, 1271.0, 1226.0, 1259.0, 1214.0, 1270.0, 1333.0, 1353.0, 1259.0, 1240.0, 1274.0, 1241.0, 1268.0, 1254.0, 1208.0, 1270.0, 1241.0, 1227.0, 1289.0, 1245.0, 1230.0, 1232.0, 1240.0, 1278.0, 1245.0, 1232.0, 1260.0, 1209.0, 1210.0, 1275.0, 1316.0, 1294.0]
train Loss: 3.8757 Acc: 2.8795
test Loss: 3.9203 Acc: 1.3750

Epoch 7/29
----------
Category Weights : [1311.0, 1247.0, 1327.0, 1188.0, 1264.0, 1191.0, 1296.0, 1251.0, 1215.0, 1280.0, 1244.0, 1258.0, 1190.0, 1298.0, 1247.0, 1308.0, 1257.0, 1291.0, 1272.0, 1335.0, 1232.0, 1295.0, 1209.0, 1231.0, 1255.0, 1233.0, 1268.0, 1250.0, 1202.0, 1241.0, 1228.0, 1269.0, 1272.0, 1269.0, 1242.0, 1201.0, 1281.0, 1213.0, 1224.0, 1250.0, 1278.0, 1258.0, 1249.0, 1261.0, 1256.0, 1306.0, 1311.0, 1297.0, 1232.0, 1233.0, 1216.0]
train Loss: 3.8699 Acc: 3.0670
test Loss: 3.9201 Acc: 1.3975

Epoch 8/29
----------
Category Weights : [1219.0, 1287.0, 1294.0, 1291.0, 1246.0, 1327.0, 1255.0, 1208.0, 1251.0, 1294.0, 1290.0, 1238.0, 1234.0, 1220.0, 1282.0, 1294.0, 1245.0, 1203.0, 1268.0, 1272.0, 1268.0, 1252.0, 1231.0, 1267.0, 1350.0, 1239.0, 1295.0, 1239.0, 1221.0, 1247.0, 1286.0, 1266.0, 1237.0, 1185.0, 1272.0, 1254.0, 1173.0, 1330.0, 1228.0, 1265.0, 1187.0, 1247.0, 1263.0, 1243.0, 1255.0, 1247.0, 1300.0, 1289.0, 1237.0, 1212.0, 1229.0]
train Loss: 3.8644 Acc: 3.2370
test Loss: 3.9170 Acc: 1.4800

Epoch 9/29
----------
Category Weights : [1188.0, 1253.0, 1270.0, 1316.0, 1244.0, 1248.0, 1255.0, 1235.0, 1239.0, 1332.0, 1253.0, 1290.0, 1224.0, 1254.0, 1245.0, 1272.0, 1217.0, 1198.0, 1265.0, 1296.0, 1208.0, 1301.0, 1228.0, 1227.0, 1215.0, 1225.0, 1294.0, 1204.0, 1294.0, 1206.0, 1323.0, 1232.0, 1239.0, 1291.0, 1247.0, 1320.0, 1278.0, 1243.0, 1234.0, 1206.0, 1259.0, 1281.0, 1255.0, 1215.0, 1307.0, 1295.0, 1265.0, 1308.0, 1223.0, 1239.0, 1276.0]
train Loss: 3.8589 Acc: 3.4325
test Loss: 3.9150 Acc: 1.6235

Epoch 10/29
----------
Category Weights : [1218.0, 1300.0, 1254.0, 1262.0, 1265.0, 1259.0, 1163.0, 1336.0, 1310.0, 1260.0, 1249.0, 1245.0, 1232.0, 1200.0, 1240.0, 1235.0, 1175.0, 1224.0, 1279.0, 1320.0, 1242.0, 1181.0, 1289.0, 1282.0, 1265.0, 1235.0, 1288.0, 1207.0, 1186.0, 1290.0, 1199.0, 1288.0, 1300.0, 1292.0, 1222.0, 1281.0, 1249.0, 1263.0, 1294.0, 1287.0, 1241.0, 1301.0, 1287.0, 1282.0, 1287.0, 1263.0, 1202.0, 1283.0, 1175.0, 1288.0, 1257.0]
train Loss: 3.8514 Acc: 3.7195
test Loss: 3.9115 Acc: 1.7210

Epoch 11/29
----------
Category Weights : [1299.0, 1227.0, 1216.0, 1223.0, 1296.0, 1244.0, 1282.0, 1265.0, 1234.0, 1221.0, 1317.0, 1226.0, 1245.0, 1210.0, 1259.0, 1201.0, 1227.0, 1278.0, 1208.0, 1273.0, 1290.0, 1201.0, 1235.0, 1248.0, 1288.0, 1256.0, 1214.0, 1230.0, 1218.0, 1224.0, 1283.0, 1238.0, 1279.0, 1295.0, 1261.0, 1309.0, 1255.0, 1225.0, 1231.0, 1247.0, 1290.0, 1275.0, 1231.0, 1276.0, 1267.0, 1315.0, 1323.0, 1268.0, 1306.0, 1280.0, 1223.0]
train Loss: 3.8471 Acc: 3.8670
test Loss: 3.9123 Acc: 1.6905

Epoch 12/29
----------
Category Weights : [1269.0, 1263.0, 1241.0, 1242.0, 1241.0, 1261.0, 1206.0, 1272.0, 1222.0, 1219.0, 1289.0, 1210.0, 1257.0, 1220.0, 1252.0, 1274.0, 1286.0, 1224.0, 1348.0, 1288.0, 1272.0, 1240.0, 1209.0, 1263.0, 1307.0, 1219.0, 1262.0, 1245.0, 1238.0, 1191.0, 1284.0, 1259.0, 1291.0, 1219.0, 1241.0, 1302.0, 1310.0, 1251.0, 1278.0, 1251.0, 1254.0, 1243.0, 1255.0, 1259.0, 1243.0, 1251.0, 1307.0, 1240.0, 1262.0, 1231.0, 1271.0]
train Loss: 3.8468 Acc: 3.8795
test Loss: 3.9129 Acc: 1.6765

Epoch 13/29
----------
Category Weights : [1204.0, 1249.0, 1238.0, 1205.0, 1229.0, 1285.0, 1243.0, 1278.0, 1262.0, 1258.0, 1259.0, 1317.0, 1285.0, 1253.0, 1226.0, 1283.0, 1266.0, 1206.0, 1275.0, 1269.0, 1238.0, 1244.0, 1325.0, 1286.0, 1219.0, 1241.0, 1264.0, 1274.0, 1279.0, 1327.0, 1212.0, 1259.0, 1230.0, 1330.0, 1316.0, 1215.0, 1270.0, 1259.0, 1266.0, 1193.0, 1238.0, 1234.0, 1205.0, 1286.0, 1234.0, 1209.0, 1305.0, 1277.0, 1255.0, 1245.0, 1207.0]
train Loss: 3.8468 Acc: 3.8795
test Loss: 3.9132 Acc: 1.6555

Epoch 14/29
----------
Category Weights : [1228.0, 1274.0, 1207.0, 1299.0, 1202.0, 1287.0, 1262.0, 1282.0, 1220.0, 1257.0, 1259.0, 1262.0, 1214.0, 1222.0, 1258.0, 1265.0, 1308.0, 1260.0, 1243.0, 1251.0, 1283.0, 1243.0, 1219.0, 1276.0, 1251.0, 1320.0, 1315.0, 1196.0, 1271.0, 1279.0, 1271.0, 1254.0, 1250.0, 1244.0, 1265.0, 1199.0, 1220.0, 1271.0, 1208.0, 1237.0, 1246.0, 1233.0, 1296.0, 1219.0, 1270.0, 1280.0, 1303.0, 1232.0, 1294.0, 1234.0, 1293.0]
train Loss: 3.8449 Acc: 3.9440
test Loss: 3.9116 Acc: 1.7235

Epoch 15/29
----------
Category Weights : [1260.0, 1333.0, 1267.0, 1275.0, 1261.0, 1319.0, 1284.0, 1232.0, 1189.0, 1293.0, 1269.0, 1243.0, 1287.0, 1210.0, 1218.0, 1182.0, 1296.0, 1313.0, 1250.0, 1277.0, 1357.0, 1258.0, 1254.0, 1258.0, 1283.0, 1257.0, 1255.0, 1242.0, 1233.0, 1312.0, 1283.0, 1269.0, 1208.0, 1188.0, 1225.0, 1259.0, 1234.0, 1217.0, 1189.0, 1195.0, 1226.0, 1200.0, 1263.0, 1252.0, 1254.0, 1285.0, 1259.0, 1253.0, 1269.0, 1258.0, 1279.0]
train Loss: 3.8430 Acc: 3.9915
test Loss: 3.9101 Acc: 1.7590

Epoch 16/29
----------
Category Weights : [1247.0, 1288.0, 1200.0, 1257.0, 1267.0, 1204.0, 1245.0, 1236.0, 1232.0, 1254.0, 1240.0, 1299.0, 1269.0, 1291.0, 1261.0, 1295.0, 1232.0, 1293.0, 1252.0, 1278.0, 1295.0, 1248.0, 1334.0, 1241.0, 1257.0, 1249.0, 1261.0, 1259.0, 1282.0, 1247.0, 1220.0, 1271.0, 1174.0, 1197.0, 1278.0, 1253.0, 1205.0, 1213.0, 1261.0, 1282.0, 1306.0, 1280.0, 1286.0, 1231.0, 1286.0, 1222.0, 1252.0, 1253.0, 1240.0, 1274.0, 1235.0]
train Loss: 3.8417 Acc: 4.0480
test Loss: 3.9106 Acc: 1.7490

Epoch 17/29
----------
Category Weights : [1305.0, 1198.0, 1273.0, 1252.0, 1283.0, 1242.0, 1227.0, 1220.0, 1245.0, 1298.0, 1280.0, 1231.0, 1255.0, 1296.0, 1274.0, 1228.0, 1269.0, 1265.0, 1261.0, 1284.0, 1272.0, 1252.0, 1215.0, 1242.0, 1201.0, 1269.0, 1294.0, 1284.0, 1200.0, 1265.0, 1218.0, 1258.0, 1257.0, 1246.0, 1306.0, 1194.0, 1285.0, 1235.0, 1238.0, 1250.0, 1238.0, 1262.0, 1242.0, 1247.0, 1228.0, 1249.0, 1267.0, 1268.0, 1281.0, 1360.0, 1223.0]
train Loss: 3.8417 Acc: 4.0375
test Loss: 3.9103 Acc: 1.7665

Epoch 18/29
----------
Category Weights : [1222.0, 1278.0, 1246.0, 1131.0, 1242.0, 1294.0, 1222.0, 1232.0, 1259.0, 1237.0, 1246.0, 1302.0, 1282.0, 1253.0, 1256.0, 1349.0, 1257.0, 1302.0, 1258.0, 1262.0, 1186.0, 1244.0, 1326.0, 1315.0, 1279.0, 1248.0, 1281.0, 1278.0, 1225.0, 1253.0, 1252.0, 1285.0, 1209.0, 1241.0, 1216.0, 1290.0, 1281.0, 1262.0, 1244.0, 1284.0, 1253.0, 1237.0, 1210.0, 1224.0, 1221.0, 1215.0, 1170.0, 1299.0, 1260.0, 1330.0, 1284.0]
train Loss: 3.8395 Acc: 4.1025
test Loss: 3.9101 Acc: 1.7830

Epoch 19/29
----------
Category Weights : [1298.0, 1226.0, 1305.0, 1252.0, 1293.0, 1326.0, 1252.0, 1259.0, 1194.0, 1281.0, 1181.0, 1207.0, 1296.0, 1257.0, 1224.0, 1283.0, 1224.0, 1276.0, 1340.0, 1260.0, 1232.0, 1242.0, 1243.0, 1293.0, 1326.0, 1226.0, 1314.0, 1262.0, 1241.0, 1187.0, 1284.0, 1237.0, 1268.0, 1294.0, 1259.0, 1300.0, 1249.0, 1206.0, 1184.0, 1268.0, 1299.0, 1193.0, 1192.0, 1235.0, 1233.0, 1236.0, 1261.0, 1269.0, 1214.0, 1286.0, 1265.0]
train Loss: 3.8384 Acc: 4.1350
test Loss: 3.9116 Acc: 1.7265

Epoch 20/29
----------
Category Weights : [1240.0, 1227.0, 1307.0, 1272.0, 1258.0, 1275.0, 1238.0, 1280.0, 1213.0, 1218.0, 1215.0, 1224.0, 1248.0, 1258.0, 1260.0, 1254.0, 1315.0, 1312.0, 1294.0, 1277.0, 1206.0, 1228.0, 1247.0, 1320.0, 1239.0, 1265.0, 1258.0, 1257.0, 1280.0, 1183.0, 1240.0, 1288.0, 1286.0, 1248.0, 1280.0, 1279.0, 1263.0, 1235.0, 1168.0, 1280.0, 1240.0, 1290.0, 1307.0, 1283.0, 1298.0, 1255.0, 1195.0, 1262.0, 1262.0, 1201.0, 1204.0]
train Loss: 3.8372 Acc: 4.1835
test Loss: 3.9111 Acc: 1.7420

Epoch 21/29
----------
Category Weights : [1231.0, 1283.0, 1282.0, 1268.0, 1206.0, 1214.0, 1306.0, 1295.0, 1226.0, 1265.0, 1195.0, 1205.0, 1222.0, 1193.0, 1242.0, 1259.0, 1210.0, 1300.0, 1305.0, 1306.0, 1276.0, 1254.0, 1333.0, 1297.0, 1280.0, 1218.0, 1286.0, 1264.0, 1243.0, 1257.0, 1247.0, 1306.0, 1218.0, 1284.0, 1215.0, 1259.0, 1241.0, 1272.0, 1271.0, 1225.0, 1302.0, 1242.0, 1253.0, 1180.0, 1321.0, 1226.0, 1218.0, 1279.0, 1267.0, 1233.0, 1252.0]
train Loss: 3.8386 Acc: 4.1385
test Loss: 3.9109 Acc: 1.7370

Epoch 22/29
----------
Category Weights : [1205.0, 1208.0, 1263.0, 1260.0, 1296.0, 1297.0, 1266.0, 1277.0, 1235.0, 1282.0, 1177.0, 1262.0, 1239.0, 1285.0, 1314.0, 1229.0, 1339.0, 1270.0, 1291.0, 1236.0, 1261.0, 1200.0, 1277.0, 1274.0, 1289.0, 1212.0, 1189.0, 1253.0, 1236.0, 1238.0, 1280.0, 1199.0, 1255.0, 1295.0, 1170.0, 1316.0, 1268.0, 1264.0, 1306.0, 1190.0, 1250.0, 1260.0, 1280.0, 1284.0, 1236.0, 1258.0, 1256.0, 1268.0, 1261.0, 1278.0, 1198.0]
train Loss: 3.8392 Acc: 4.1185
test Loss: 3.9110 Acc: 1.7415

Epoch 23/29
----------
Category Weights : [1249.0, 1248.0, 1293.0, 1214.0, 1171.0, 1290.0, 1271.0, 1342.0, 1287.0, 1234.0, 1257.0, 1261.0, 1251.0, 1185.0, 1255.0, 1273.0, 1231.0, 1234.0, 1234.0, 1253.0, 1293.0, 1246.0, 1252.0, 1296.0, 1293.0, 1269.0, 1232.0, 1227.0, 1229.0, 1273.0, 1259.0, 1288.0, 1255.0, 1314.0, 1220.0, 1245.0, 1271.0, 1321.0, 1225.0, 1217.0, 1218.0, 1202.0, 1241.0, 1248.0, 1268.0, 1212.0, 1262.0, 1277.0, 1295.0, 1260.0, 1291.0]
train Loss: 3.8358 Acc: 4.2420
test Loss: 3.9110 Acc: 1.7400

Epoch 24/29
----------
Category Weights : [1286.0, 1267.0, 1263.0, 1280.0, 1242.0, 1184.0, 1261.0, 1172.0, 1294.0, 1307.0, 1225.0, 1282.0, 1259.0, 1235.0, 1265.0, 1273.0, 1290.0, 1287.0, 1258.0, 1262.0, 1235.0, 1288.0, 1183.0, 1228.0, 1308.0, 1264.0, 1245.0, 1296.0, 1321.0, 1261.0, 1280.0, 1230.0, 1273.0, 1279.0, 1170.0, 1209.0, 1204.0, 1237.0, 1272.0, 1190.0, 1352.0, 1232.0, 1257.0, 1255.0, 1249.0, 1239.0, 1284.0, 1231.0, 1235.0, 1313.0, 1220.0]
train Loss: 3.8364 Acc: 4.2110
test Loss: 3.9106 Acc: 1.7615

Epoch 25/29
----------
Category Weights : [1282.0, 1270.0, 1241.0, 1289.0, 1315.0, 1205.0, 1312.0, 1219.0, 1296.0, 1274.0, 1255.0, 1280.0, 1240.0, 1299.0, 1257.0, 1253.0, 1275.0, 1217.0, 1286.0, 1198.0, 1282.0, 1256.0, 1251.0, 1194.0, 1258.0, 1304.0, 1238.0, 1228.0, 1230.0, 1289.0, 1203.0, 1255.0, 1289.0, 1266.0, 1270.0, 1245.0, 1185.0, 1246.0, 1224.0, 1269.0, 1264.0, 1339.0, 1235.0, 1296.0, 1218.0, 1218.0, 1286.0, 1226.0, 1228.0, 1234.0, 1243.0]
train Loss: 3.8350 Acc: 4.2755
test Loss: 3.9113 Acc: 1.7395

Epoch 26/29
----------
Category Weights : [1221.0, 1243.0, 1236.0, 1234.0, 1244.0, 1215.0, 1254.0, 1227.0, 1303.0, 1236.0, 1345.0, 1208.0, 1317.0, 1319.0, 1209.0, 1233.0, 1229.0, 1249.0, 1304.0, 1329.0, 1275.0, 1241.0, 1253.0, 1255.0, 1217.0, 1244.0, 1232.0, 1206.0, 1242.0, 1266.0, 1288.0, 1229.0, 1259.0, 1208.0, 1263.0, 1246.0, 1200.0, 1266.0, 1293.0, 1254.0, 1285.0, 1216.0, 1197.0, 1293.0, 1277.0, 1232.0, 1297.0, 1258.0, 1285.0, 1275.0, 1325.0]
train Loss: 3.8371 Acc: 4.1890
test Loss: 3.9105 Acc: 1.7675

Epoch 27/29
----------
Category Weights : [1302.0, 1295.0, 1250.0, 1177.0, 1299.0, 1290.0, 1241.0, 1277.0, 1230.0, 1264.0, 1235.0, 1240.0, 1351.0, 1273.0, 1261.0, 1199.0, 1321.0, 1231.0, 1270.0, 1242.0, 1294.0, 1198.0, 1226.0, 1238.0, 1191.0, 1316.0, 1291.0, 1305.0, 1280.0, 1253.0, 1270.0, 1271.0, 1306.0, 1258.0, 1147.0, 1314.0, 1250.0, 1249.0, 1191.0, 1183.0, 1242.0, 1257.0, 1236.0, 1232.0, 1239.0, 1188.0, 1236.0, 1343.0, 1272.0, 1205.0, 1303.0]
train Loss: 3.8344 Acc: 4.2830
test Loss: 3.9109 Acc: 1.7590

Epoch 28/29
----------
Category Weights : [1276.0, 1257.0, 1227.0, 1249.0, 1208.0, 1261.0, 1240.0, 1240.0, 1233.0, 1267.0, 1273.0, 1266.0, 1284.0, 1247.0, 1226.0, 1212.0, 1280.0, 1262.0, 1274.0, 1267.0, 1315.0, 1276.0, 1260.0, 1282.0, 1291.0, 1276.0, 1243.0, 1279.0, 1260.0, 1280.0, 1247.0, 1244.0, 1209.0, 1243.0, 1257.0, 1242.0, 1287.0, 1282.0, 1296.0, 1214.0, 1227.0, 1167.0, 1204.0, 1226.0, 1309.0, 1247.0, 1289.0, 1216.0, 1299.0, 1278.0, 1238.0]
train Loss: 3.8365 Acc: 4.2110
test Loss: 3.9109 Acc: 1.7610

Epoch 29/29
----------
Category Weights : [1258.0, 1303.0, 1215.0, 1213.0, 1264.0, 1240.0, 1254.0, 1292.0, 1269.0, 1218.0, 1285.0, 1303.0, 1309.0, 1300.0, 1248.0, 1217.0, 1209.0, 1254.0, 1264.0, 1293.0, 1303.0, 1226.0, 1274.0, 1262.0, 1276.0, 1258.0, 1270.0, 1237.0, 1274.0, 1233.0, 1265.0, 1244.0, 1230.0, 1289.0, 1270.0, 1260.0, 1253.0, 1227.0, 1200.0, 1231.0, 1184.0, 1215.0, 1286.0, 1246.0, 1326.0, 1272.0, 1210.0, 1227.0, 1267.0, 1266.0, 1243.0]
train Loss: 3.8350 Acc: 4.2635
test Loss: 3.9103 Acc: 1.7715

Training complete in 80m 9s
Best val Acc: 1.783000
Model saved to disk... : logs/bovgru_HA_of20_Hidden256/gru_classifier_ep30_S30C100_SGD.pt
Loading Encoder weights... : logs/bovgru_HA_of20_Hidden256/gru_classifier_ep30_S30C100_SGD.pt
Total Execution time for 30 epoch : 4809.092903375626
##############################
GRU Sequence Classification Results:
99/1516 Correct
Accuracy = 0.06530343007915568 
Confusion matrix
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
#Parameters : 2142259 
************************************************************
SEQ_SIZES : range(30, 31, 2)
Accuracy values : [0.06530343007915568]







For I3DFine Extracted feats SEQ 16 STEP 8 BOVGRU HA

INP_VEC_SIZE =  1024
Clustering using KMeans: Input size -> (37786, 1024) :: n_clusters -> 100
Done Clustering!
Writing the KMeans models to disk...
Create numpy one hot representation for train features...

Epoch 0/29
----------
Category Weights : [623.0, 638.0, 622.0, 600.0, 632.0, 605.0, 626.0, 646.0, 586.0, 623.0, 618.0, 572.0, 638.0, 642.0, 656.0, 636.0, 601.0, 626.0, 574.0, 606.0, 646.0, 615.0, 632.0, 626.0, 618.0, 655.0, 612.0, 626.0, 618.0, 639.0, 641.0, 639.0, 649.0, 639.0, 612.0, 640.0, 603.0, 661.0, 640.0, 686.0, 620.0, 617.0, 650.0, 635.0, 593.0, 621.0, 647.0, 632.0, 630.0, 609.0, 619.0]
train Loss: 0.1172 Acc: 0.2200
test Loss: 0.1228 Acc: 0.0384

Epoch 1/29
----------
Category Weights : [654.0, 602.0, 595.0, 666.0, 626.0, 600.0, 607.0, 651.0, 662.0, 636.0, 623.0, 630.0, 645.0, 590.0, 630.0, 619.0, 642.0, 608.0, 655.0, 641.0, 646.0, 628.0, 642.0, 624.0, 643.0, 639.0, 601.0, 627.0, 646.0, 611.0, 612.0, 651.0, 620.0, 599.0, 635.0, 624.0, 606.0, 587.0, 618.0, 632.0, 650.0, 609.0, 627.0, 650.0, 644.0, 657.0, 613.0, 612.0, 585.0, 611.0, 609.0]
train Loss: 0.1170 Acc: 0.2236
test Loss: 0.1226 Acc: 0.0442

Epoch 2/29
----------
Category Weights : [629.0, 652.0, 662.0, 667.0, 603.0, 667.0, 646.0, 626.0, 612.0, 634.0, 614.0, 625.0, 623.0, 619.0, 651.0, 641.0, 609.0, 616.0, 674.0, 584.0, 608.0, 641.0, 632.0, 625.0, 615.0, 642.0, 630.0, 621.0, 619.0, 599.0, 571.0, 623.0, 602.0, 594.0, 630.0, 657.0, 635.0, 595.0, 649.0, 619.0, 660.0, 614.0, 616.0, 591.0, 613.0, 630.0, 659.0, 606.0, 617.0, 644.0, 629.0]
train Loss: 0.1168 Acc: 0.2301
test Loss: 0.1226 Acc: 0.0473

Epoch 3/29
----------
Category Weights : [627.0, 640.0, 611.0, 611.0, 608.0, 679.0, 617.0, 664.0, 640.0, 624.0, 634.0, 609.0, 597.0, 616.0, 633.0, 642.0, 622.0, 641.0, 603.0, 611.0, 664.0, 654.0, 629.0, 610.0, 604.0, 631.0, 658.0, 596.0, 630.0, 601.0, 649.0, 566.0, 619.0, 618.0, 604.0, 655.0, 624.0, 627.0, 609.0, 618.0, 639.0, 618.0, 589.0, 603.0, 660.0, 660.0, 647.0, 624.0, 648.0, 658.0, 599.0]
train Loss: 0.1169 Acc: 0.2278
test Loss: 0.1227 Acc: 0.0422

Epoch 4/29
----------
Category Weights : [636.0, 618.0, 628.0, 645.0, 617.0, 626.0, 678.0, 593.0, 631.0, 651.0, 644.0, 580.0, 647.0, 623.0, 609.0, 633.0, 601.0, 653.0, 607.0, 584.0, 655.0, 648.0, 668.0, 609.0, 647.0, 670.0, 607.0, 600.0, 655.0, 589.0, 650.0, 614.0, 628.0, 664.0, 652.0, 594.0, 623.0, 673.0, 596.0, 637.0, 628.0, 630.0, 615.0, 599.0, 619.0, 588.0, 636.0, 550.0, 635.0, 630.0, 627.0]
train Loss: 0.1171 Acc: 0.2220
test Loss: 0.1226 Acc: 0.0445

Epoch 5/29
----------
Category Weights : [602.0, 662.0, 577.0, 614.0, 658.0, 661.0, 617.0, 622.0, 662.0, 617.0, 656.0, 664.0, 639.0, 622.0, 642.0, 634.0, 602.0, 645.0, 623.0, 647.0, 620.0, 634.0, 581.0, 618.0, 637.0, 602.0, 621.0, 607.0, 584.0, 658.0, 640.0, 591.0, 616.0, 628.0, 603.0, 646.0, 617.0, 596.0, 649.0, 623.0, 617.0, 621.0, 639.0, 620.0, 617.0, 664.0, 600.0, 676.0, 610.0, 617.0, 622.0]
train Loss: 0.1170 Acc: 0.2246
test Loss: 0.1225 Acc: 0.0480

Epoch 6/29
----------
Category Weights : [635.0, 610.0, 607.0, 636.0, 642.0, 570.0, 618.0, 637.0, 577.0, 607.0, 611.0, 630.0, 613.0, 609.0, 624.0, 625.0, 602.0, 621.0, 619.0, 629.0, 661.0, 639.0, 665.0, 601.0, 577.0, 639.0, 664.0, 604.0, 624.0, 616.0, 617.0, 646.0, 564.0, 623.0, 626.0, 617.0, 623.0, 658.0, 642.0, 651.0, 639.0, 640.0, 696.0, 654.0, 635.0, 655.0, 654.0, 633.0, 586.0, 643.0, 626.0]
train Loss: 0.1171 Acc: 0.2201
test Loss: 0.1226 Acc: 0.0460

Epoch 7/29
----------
Category Weights : [636.0, 651.0, 651.0, 646.0, 633.0, 597.0, 611.0, 585.0, 644.0, 661.0, 623.0, 611.0, 607.0, 631.0, 641.0, 619.0, 610.0, 624.0, 632.0, 650.0, 630.0, 625.0, 591.0, 602.0, 594.0, 612.0, 666.0, 633.0, 652.0, 596.0, 597.0, 657.0, 614.0, 608.0, 627.0, 654.0, 626.0, 661.0, 617.0, 631.0, 609.0, 646.0, 653.0, 624.0, 634.0, 623.0, 671.0, 596.0, 665.0, 578.0, 585.0]
train Loss: 0.1171 Acc: 0.2208
test Loss: 0.1227 Acc: 0.0421

Epoch 8/29
----------
Category Weights : [626.0, 648.0, 637.0, 629.0, 620.0, 675.0, 612.0, 664.0, 624.0, 611.0, 672.0, 621.0, 590.0, 580.0, 643.0, 604.0, 630.0, 659.0, 619.0, 626.0, 643.0, 626.0, 632.0, 607.0, 662.0, 637.0, 586.0, 620.0, 617.0, 617.0, 633.0, 668.0, 612.0, 618.0, 644.0, 633.0, 590.0, 582.0, 624.0, 635.0, 662.0, 608.0, 611.0, 663.0, 589.0, 618.0, 611.0, 630.0, 624.0, 598.0, 650.0]
train Loss: 0.1169 Acc: 0.2276
test Loss: 0.1227 Acc: 0.0443

Epoch 9/29
----------
Category Weights : [593.0, 692.0, 626.0, 662.0, 621.0, 663.0, 586.0, 615.0, 643.0, 682.0, 656.0, 631.0, 633.0, 648.0, 640.0, 620.0, 582.0, 603.0, 658.0, 628.0, 650.0, 631.0, 609.0, 626.0, 613.0, 630.0, 612.0, 645.0, 619.0, 598.0, 590.0, 617.0, 616.0, 618.0, 553.0, 636.0, 624.0, 628.0, 650.0, 634.0, 672.0, 633.0, 606.0, 663.0, 590.0, 622.0, 616.0, 591.0, 639.0, 621.0, 606.0]
train Loss: 0.1170 Acc: 0.2243
test Loss: 0.1229 Acc: 0.0379

Epoch 10/29
----------
Category Weights : [608.0, 650.0, 600.0, 580.0, 600.0, 638.0, 648.0, 633.0, 639.0, 578.0, 597.0, 634.0, 595.0, 622.0, 590.0, 588.0, 594.0, 621.0, 581.0, 659.0, 642.0, 691.0, 628.0, 640.0, 620.0, 658.0, 642.0, 619.0, 631.0, 662.0, 639.0, 593.0, 637.0, 611.0, 631.0, 606.0, 591.0, 619.0, 652.0, 625.0, 638.0, 651.0, 575.0, 621.0, 612.0, 625.0, 658.0, 677.0, 637.0, 664.0, 690.0]
train Loss: 0.1168 Acc: 0.2297
test Loss: 0.1228 Acc: 0.0399

Epoch 11/29
----------
Category Weights : [631.0, 673.0, 631.0, 624.0, 593.0, 602.0, 632.0, 660.0, 596.0, 676.0, 695.0, 577.0, 624.0, 621.0, 633.0, 651.0, 611.0, 633.0, 594.0, 647.0, 594.0, 597.0, 651.0, 601.0, 656.0, 645.0, 611.0, 597.0, 611.0, 625.0, 653.0, 653.0, 614.0, 587.0, 651.0, 657.0, 617.0, 621.0, 593.0, 635.0, 605.0, 579.0, 635.0, 633.0, 628.0, 645.0, 661.0, 571.0, 631.0, 636.0, 643.0]
train Loss: 0.1169 Acc: 0.2266
test Loss: 0.1228 Acc: 0.0400

Epoch 12/29
----------
Category Weights : [635.0, 603.0, 651.0, 627.0, 652.0, 675.0, 594.0, 666.0, 602.0, 586.0, 657.0, 605.0, 644.0, 607.0, 621.0, 620.0, 639.0, 614.0, 634.0, 640.0, 628.0, 579.0, 620.0, 655.0, 644.0, 644.0, 658.0, 665.0, 586.0, 656.0, 663.0, 565.0, 626.0, 631.0, 599.0, 604.0, 667.0, 648.0, 580.0, 593.0, 639.0, 641.0, 591.0, 616.0, 610.0, 606.0, 632.0, 634.0, 617.0, 652.0, 619.0]
train Loss: 0.1168 Acc: 0.2313
test Loss: 0.1228 Acc: 0.0400

Epoch 13/29
----------
Category Weights : [638.0, 644.0, 618.0, 625.0, 620.0, 655.0, 570.0, 629.0, 639.0, 625.0, 627.0, 649.0, 617.0, 582.0, 640.0, 614.0, 632.0, 586.0, 585.0, 629.0, 609.0, 625.0, 667.0, 629.0, 632.0, 680.0, 639.0, 659.0, 592.0, 610.0, 626.0, 606.0, 652.0, 635.0, 659.0, 638.0, 618.0, 604.0, 595.0, 634.0, 695.0, 635.0, 647.0, 610.0, 599.0, 608.0, 644.0, 643.0, 633.0, 583.0, 610.0]
train Loss: 0.1167 Acc: 0.2335
test Loss: 0.1228 Acc: 0.0399

Epoch 14/29
----------
Category Weights : [594.0, 619.0, 627.0, 645.0, 653.0, 648.0, 648.0, 631.0, 624.0, 641.0, 615.0, 653.0, 669.0, 639.0, 588.0, 591.0, 628.0, 627.0, 627.0, 637.0, 630.0, 606.0, 570.0, 643.0, 627.0, 646.0, 612.0, 577.0, 652.0, 671.0, 602.0, 583.0, 602.0, 635.0, 616.0, 639.0, 668.0, 649.0, 608.0, 619.0, 617.0, 651.0, 611.0, 661.0, 624.0, 641.0, 595.0, 623.0, 575.0, 633.0, 650.0]
train Loss: 0.1167 Acc: 0.2326
test Loss: 0.1228 Acc: 0.0403

Epoch 15/29
----------
Category Weights : [652.0, 627.0, 612.0, 616.0, 644.0, 607.0, 616.0, 654.0, 631.0, 628.0, 670.0, 665.0, 630.0, 599.0, 641.0, 654.0, 606.0, 627.0, 640.0, 593.0, 620.0, 583.0, 642.0, 644.0, 629.0, 611.0, 615.0, 611.0, 586.0, 610.0, 631.0, 599.0, 602.0, 605.0, 591.0, 571.0, 638.0, 634.0, 606.0, 657.0, 662.0, 654.0, 661.0, 641.0, 622.0, 648.0, 684.0, 643.0, 603.0, 590.0, 635.0]
train Loss: 0.1168 Acc: 0.2293
test Loss: 0.1228 Acc: 0.0404

Epoch 16/29
----------
Category Weights : [620.0, 629.0, 649.0, 580.0, 655.0, 649.0, 609.0, 621.0, 601.0, 591.0, 664.0, 640.0, 604.0, 604.0, 573.0, 630.0, 583.0, 651.0, 642.0, 591.0, 594.0, 650.0, 598.0, 646.0, 602.0, 637.0, 620.0, 569.0, 612.0, 610.0, 639.0, 654.0, 656.0, 601.0, 644.0, 589.0, 661.0, 636.0, 662.0, 664.0, 626.0, 623.0, 692.0, 609.0, 641.0, 661.0, 607.0, 663.0, 638.0, 614.0, 636.0]
train Loss: 0.1167 Acc: 0.2335
test Loss: 0.1228 Acc: 0.0403

Epoch 17/29
----------
Category Weights : [609.0, 637.0, 607.0, 640.0, 624.0, 628.0, 599.0, 661.0, 697.0, 634.0, 651.0, 655.0, 644.0, 644.0, 608.0, 578.0, 633.0, 638.0, 624.0, 617.0, 646.0, 644.0, 588.0, 599.0, 604.0, 638.0, 619.0, 644.0, 629.0, 608.0, 660.0, 592.0, 619.0, 592.0, 633.0, 626.0, 640.0, 656.0, 652.0, 609.0, 563.0, 625.0, 625.0, 652.0, 635.0, 596.0, 650.0, 649.0, 568.0, 635.0, 616.0]
train Loss: 0.1167 Acc: 0.2336
test Loss: 0.1228 Acc: 0.0405

Epoch 18/29
----------
Category Weights : [628.0, 645.0, 683.0, 592.0, 620.0, 615.0, 599.0, 612.0, 667.0, 675.0, 638.0, 647.0, 615.0, 640.0, 571.0, 617.0, 633.0, 574.0, 631.0, 655.0, 605.0, 621.0, 657.0, 582.0, 634.0, 608.0, 617.0, 634.0, 616.0, 664.0, 630.0, 636.0, 650.0, 644.0, 622.0, 622.0, 663.0, 643.0, 612.0, 662.0, 625.0, 622.0, 610.0, 550.0, 620.0, 612.0, 639.0, 623.0, 560.0, 673.0, 627.0]
train Loss: 0.1167 Acc: 0.2334
test Loss: 0.1227 Acc: 0.0416

Epoch 19/29
----------
Category Weights : [660.0, 604.0, 636.0, 656.0, 642.0, 630.0, 656.0, 621.0, 665.0, 603.0, 610.0, 613.0, 613.0, 662.0, 621.0, 613.0, 597.0, 576.0, 646.0, 653.0, 639.0, 640.0, 701.0, 646.0, 674.0, 642.0, 634.0, 663.0, 638.0, 610.0, 596.0, 572.0, 565.0, 621.0, 599.0, 653.0, 626.0, 623.0, 591.0, 616.0, 679.0, 610.0, 610.0, 580.0, 626.0, 631.0, 611.0, 606.0, 614.0, 627.0, 620.0]
train Loss: 0.1167 Acc: 0.2345
test Loss: 0.1228 Acc: 0.0413

Epoch 20/29
----------
Category Weights : [646.0, 618.0, 642.0, 608.0, 605.0, 608.0, 645.0, 599.0, 577.0, 642.0, 671.0, 650.0, 659.0, 651.0, 589.0, 615.0, 623.0, 581.0, 618.0, 603.0, 627.0, 645.0, 637.0, 621.0, 565.0, 590.0, 651.0, 600.0, 649.0, 630.0, 613.0, 630.0, 654.0, 635.0, 616.0, 638.0, 656.0, 619.0, 621.0, 665.0, 663.0, 579.0, 615.0, 635.0, 657.0, 647.0, 595.0, 622.0, 633.0, 655.0, 627.0]
train Loss: 0.1165 Acc: 0.2404
test Loss: 0.1228 Acc: 0.0413

Epoch 21/29
----------
Category Weights : [609.0, 642.0, 602.0, 598.0, 623.0, 650.0, 603.0, 647.0, 629.0, 642.0, 600.0, 579.0, 623.0, 619.0, 662.0, 590.0, 619.0, 664.0, 610.0, 670.0, 626.0, 606.0, 630.0, 636.0, 651.0, 628.0, 610.0, 621.0, 648.0, 611.0, 620.0, 585.0, 616.0, 637.0, 667.0, 631.0, 605.0, 662.0, 619.0, 621.0, 653.0, 622.0, 653.0, 608.0, 573.0, 632.0, 629.0, 633.0, 620.0, 629.0, 677.0]
train Loss: 0.1167 Acc: 0.2339
test Loss: 0.1228 Acc: 0.0412

Epoch 22/29
----------
Category Weights : [654.0, 585.0, 600.0, 665.0, 608.0, 647.0, 598.0, 606.0, 626.0, 626.0, 663.0, 621.0, 632.0, 652.0, 623.0, 625.0, 606.0, 634.0, 628.0, 703.0, 606.0, 636.0, 634.0, 607.0, 644.0, 589.0, 617.0, 627.0, 617.0, 662.0, 635.0, 592.0, 609.0, 664.0, 596.0, 618.0, 590.0, 618.0, 617.0, 609.0, 664.0, 655.0, 608.0, 662.0, 618.0, 593.0, 629.0, 644.0, 636.0, 606.0, 636.0]
train Loss: 0.1166 Acc: 0.2376
test Loss: 0.1228 Acc: 0.0412

Epoch 23/29
----------
Category Weights : [614.0, 624.0, 633.0, 563.0, 653.0, 611.0, 631.0, 598.0, 632.0, 630.0, 637.0, 598.0, 603.0, 603.0, 622.0, 609.0, 658.0, 623.0, 629.0, 628.0, 620.0, 599.0, 642.0, 602.0, 678.0, 663.0, 607.0, 656.0, 631.0, 626.0, 578.0, 635.0, 696.0, 666.0, 602.0, 633.0, 629.0, 602.0, 631.0, 625.0, 655.0, 627.0, 623.0, 659.0, 645.0, 631.0, 623.0, 617.0, 596.0, 595.0, 649.0]
train Loss: 0.1167 Acc: 0.2347
test Loss: 0.1228 Acc: 0.0413

Epoch 24/29
----------
Category Weights : [662.0, 644.0, 580.0, 614.0, 626.0, 634.0, 616.0, 625.0, 626.0, 567.0, 579.0, 653.0, 608.0, 637.0, 627.0, 612.0, 618.0, 616.0, 660.0, 628.0, 572.0, 639.0, 639.0, 658.0, 596.0, 667.0, 604.0, 609.0, 623.0, 623.0, 647.0, 608.0, 657.0, 656.0, 620.0, 635.0, 605.0, 633.0, 620.0, 681.0, 630.0, 660.0, 615.0, 586.0, 621.0, 601.0, 669.0, 623.0, 622.0, 658.0, 631.0]
train Loss: 0.1167 Acc: 0.2337
test Loss: 0.1228 Acc: 0.0412

Epoch 25/29
----------
Category Weights : [650.0, 678.0, 659.0, 688.0, 612.0, 650.0, 607.0, 640.0, 597.0, 651.0, 654.0, 620.0, 615.0, 594.0, 609.0, 636.0, 648.0, 587.0, 640.0, 655.0, 626.0, 609.0, 633.0, 548.0, 606.0, 619.0, 620.0, 639.0, 619.0, 639.0, 608.0, 615.0, 613.0, 679.0, 625.0, 653.0, 627.0, 602.0, 643.0, 642.0, 610.0, 598.0, 613.0, 574.0, 707.0, 583.0, 603.0, 615.0, 626.0, 633.0, 623.0]
train Loss: 0.1168 Acc: 0.2300
test Loss: 0.1228 Acc: 0.0411

Epoch 26/29
----------
Category Weights : [643.0, 625.0, 641.0, 668.0, 662.0, 642.0, 632.0, 656.0, 619.0, 611.0, 654.0, 639.0, 627.0, 636.0, 589.0, 608.0, 608.0, 605.0, 639.0, 608.0, 639.0, 597.0, 639.0, 619.0, 569.0, 651.0, 623.0, 611.0, 638.0, 569.0, 643.0, 641.0, 629.0, 642.0, 660.0, 611.0, 616.0, 577.0, 617.0, 679.0, 640.0, 600.0, 616.0, 640.0, 617.0, 628.0, 604.0, 613.0, 634.0, 658.0, 608.0]
train Loss: 0.1167 Acc: 0.2348
test Loss: 0.1228 Acc: 0.0411

Epoch 27/29
----------
Category Weights : [572.0, 587.0, 609.0, 621.0, 608.0, 640.0, 641.0, 642.0, 588.0, 642.0, 624.0, 668.0, 678.0, 632.0, 621.0, 647.0, 638.0, 634.0, 633.0, 615.0, 589.0, 632.0, 650.0, 657.0, 609.0, 646.0, 612.0, 622.0, 612.0, 636.0, 629.0, 622.0, 674.0, 605.0, 638.0, 598.0, 598.0, 643.0, 585.0, 666.0, 609.0, 607.0, 626.0, 672.0, 628.0, 649.0, 645.0, 582.0, 608.0, 615.0, 636.0]
train Loss: 0.1166 Acc: 0.2368
test Loss: 0.1228 Acc: 0.0412

Epoch 28/29
----------
Category Weights : [597.0, 624.0, 625.0, 649.0, 589.0, 594.0, 658.0, 607.0, 663.0, 580.0, 604.0, 604.0, 642.0, 602.0, 634.0, 614.0, 614.0, 635.0, 606.0, 653.0, 645.0, 623.0, 635.0, 688.0, 647.0, 619.0, 645.0, 614.0, 622.0, 637.0, 648.0, 650.0, 550.0, 685.0, 596.0, 595.0, 646.0, 605.0, 591.0, 646.0, 659.0, 598.0, 627.0, 643.0, 625.0, 602.0, 632.0, 614.0, 651.0, 655.0, 653.0]
train Loss: 0.1166 Acc: 0.2374
test Loss: 0.1228 Acc: 0.0412

Epoch 29/29
----------
Category Weights : [590.0, 691.0, 602.0, 597.0, 636.0, 613.0, 630.0, 646.0, 640.0, 674.0, 685.0, 635.0, 612.0, 624.0, 626.0, 674.0, 632.0, 632.0, 615.0, 628.0, 580.0, 658.0, 592.0, 608.0, 638.0, 607.0, 626.0, 706.0, 651.0, 599.0, 627.0, 588.0, 657.0, 652.0, 647.0, 615.0, 611.0, 628.0, 614.0, 609.0, 610.0, 606.0, 630.0, 629.0, 614.0, 619.0, 610.0, 594.0, 614.0, 607.0, 612.0]
train Loss: 0.1167 Acc: 0.2345
test Loss: 0.1228 Acc: 0.0412

Training complete in 9m 51s
Best val Acc: 0.048032
Model saved to disk... : logs/bovgru_HA_i3dFine_hmdb51/gru_classifier_ep30_S30C100_SGD.pt

Clusters : 
[785.0, 138.0, 428.0, 345.0, 117.0, 183.0, 352.0, 318.0, 123.0, 30.0, 11.0, 53.0, 149.0, 214.0, 227.0, 31.0, 277.0, 731.0, 369.0, 821.0, 72.0, 257.0, 337.0, 698.0, 81.0, 330.0, 225.0, 356.0, 237.0, 318.0, 175.0, 351.0, 97.0, 54.0, 28.0, 277.0, 273.0, 215.0, 340.0, 596.0, 91.0, 307.0, 400.0, 408.0, 187.0, 90.0, 358.0, 503.0, 28.0, 116.0, 140.0, 167.0, 128.0, 210.0, 375.0, 209.0, 83.0, 388.0, 85.0, 253.0, 657.0, 167.0, 201.0, 235.0, 371.0, 309.0, 38.0, 244.0, 4.0, 476.0, 354.0, 392.0, 47.0, 149.0, 208.0, 192.0, 442.0, 370.0, 228.0, 475.0, 127.0, 178.0, 1779.0, 333.0, 21.0, 306.0, 35.0, 248.0, 177.0, 110.0, 292.0, 333.0, 259.0, 178.0, 79.0, 66.0, 39.0, 174.0, 126.0, 310.0]
##############################
GRU Sequence Classification Results:
87/1516 Correct
Accuracy = 0.05738786279683377 
Confusion matrix
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 7. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
#Parameters : 2142259 
************************************************************
SEQ_SIZES : range(30, 31, 2)
Accuracy values : [0.05738786279683377]



